{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# download test images"
      ],
      "metadata": {
        "id": "Fi1bjMgUR8As"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RPTpJEkRs0W",
        "outputId": "cd9371d2-ecb6-4c70-d418-cb0f8fffca63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1GL_Rh1N-WjrvF_-YOKOyvq0zrV6TF4hb into /content/dataset.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1GL_Rh1N-WjrvF_-YOKOyvq0zrV6TF4hb',\n",
        "                                    dest_path='/content/dataset.zip',\n",
        "                                    unzip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download the weight"
      ],
      "metadata": {
        "id": "ouioMqmiSVp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdd.download_file_from_google_drive(file_id='162is67vW9CYdYyh9vk8W76UMfmORygCS',\n",
        "                                    dest_path='/content/edsr_350000.h5',\n",
        "                                    unzip=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVYo3pfKSg-V",
        "outputId": "bed4f668-5591-47ac-9f88-2c95a578a723"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 162is67vW9CYdYyh9vk8W76UMfmORygCS into /content/edsr_350000.h5... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDSR model"
      ],
      "metadata": {
        "id": "1_i4rH43S3fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.data.experimental import AUTOTUNE\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Add, Conv2D, Input, Lambda\n",
        "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
        "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.experimental.set_policy(policy) \n",
        "import time\n",
        "import os\n",
        "\n",
        "def normalize(x,rgb_mean=DIV2K_RGB_MEAN):\n",
        "    '''This function will normalize image by substracting RGB mean from image'''\n",
        "    return (x - rgb_mean) / 127.5\n",
        "\n",
        "def denormalize(x,rgb_mean=DIV2K_RGB_MEAN):\n",
        "    ''' This function will denormalize image by adding back rgb_mean'''\n",
        "    return (x * 127.5 )+ rgb_mean\n",
        "\n",
        "def shuffle_pixels(scale):\n",
        "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
        "\n",
        "def ResBlock(x_input, num_filters, scaling):\n",
        "    '''Thpis function Implementes Proposed ResBlock Architecture as per EDSR paper'''\n",
        "    # proposed ResBlock ==> Conv --> Relu --> Conv --> Scaling(mul) --> Add\n",
        "    x = Conv2D(num_filters, 3, padding='same', activation='relu')(x_input)\n",
        "    x = Conv2D(num_filters, 3, padding='same')(x)\n",
        "    if scaling:\n",
        "        x = Lambda(lambda t: t * scaling)(x)\n",
        "    x = Add()([x_input, x])\n",
        "    return x\n",
        "\n",
        "def Upsampling(x, scale, num_filters):\n",
        "    '''This function upsampling as mentioned in EDSR paper'''\n",
        "    def upsample(x, factor, **kwargs):\n",
        "        x = Conv2D(num_filters * (factor ** 2), 3, padding='same', **kwargs)(x)\n",
        "        return Lambda(shuffle_pixels(scale=factor))(x)\n",
        "\n",
        "    if scale == 2:\n",
        "        x = upsample(x, 2, name='conv2d_1_scale_2')\n",
        "    elif scale == 3:\n",
        "        x = upsample(x, 3, name='conv2d_1_scale_3')\n",
        "    elif scale == 4:\n",
        "        x = upsample(x, 2, name='conv2d_1_scale_2')\n",
        "        x = upsample(x, 2, name='conv2d_2_scale_2')\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def EDSR(scale, num_filters=64, res_blocks=8, res_block_scaling=None):\n",
        "    x_input = Input(shape=(None, None, 3))\n",
        "    # Normalize input with DIV2K_RGB_MEAN\n",
        "    x = Lambda(normalize)(x_input)\n",
        "    \n",
        "    # assign value of x to x_res block for further operations\n",
        "    x = x_res_block = Conv2D(num_filters, 3, padding='same')(x)\n",
        "\n",
        "    # Goes in number of res block\n",
        "    for i in range(res_blocks):\n",
        "        x_res_block = ResBlock(x_res_block, num_filters, res_block_scaling)\n",
        "    # convolution\n",
        "    x_res_block = Conv2D(num_filters, 3, padding='same')(x_res_block)\n",
        "    # add res_block output and original normalizwd input\n",
        "    x = Add()([x, x_res_block])\n",
        "\n",
        "    # upsampling\n",
        "    x = Upsampling(x, scale, num_filters)\n",
        "    x = Conv2D(3, 3, padding='same')(x)\n",
        "    \n",
        "    # denormalize to get back original form\n",
        "    x = Lambda(denormalize)(x)\n",
        "    return Model(x_input, x, name=\"EDSR\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW0bVaCVTA8l",
        "outputId": "dd2e1d40-fe99-47af-cc14-efe898296791"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla P100-PCIE-16GB, compute capability 6.0\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale.py:52: DynamicLossScale.__init__ (from tensorflow.python.training.experimental.loss_scale) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras.mixed_precision.LossScaleOptimizer instead. LossScaleOptimizer now has all the functionality of DynamicLossScale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = EDSR(scale=3,res_blocks=16)\n",
        "new_model.load_weights('/content/edsr_350000.h5')"
      ],
      "metadata": {
        "id": "WuLHWxpFS5nt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reproduce the result"
      ],
      "metadata": {
        "id": "V0j7Mlw_Tx4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/result')"
      ],
      "metadata": {
        "id": "_Bx7-VU7T05b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "test_dir = '/content/testing_lr_images/testing_lr_images/'\n",
        "for file_name in os.listdir(test_dir):\n",
        "  print(file_name)\n",
        "  path = test_dir + file_name\n",
        "  img = cv2.imread(path)\n",
        "\n",
        "  img = tf.expand_dims(img,axis=0)\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  sr_img = new_model(img)\n",
        "  sr_img = tf.clip_by_value(sr_img, 0, 255)\n",
        "  sr_img = tf.round(sr_img)\n",
        "  sr_img = tf.cast(sr_img, tf.uint8)\n",
        "  result = np.reshape(sr_img.numpy(), (sr_img.numpy().shape[1], sr_img.numpy().shape[2],3))\n",
        "\n",
        "  des = '/content/result/'+file_name[:-4]+'_pred.png'\n",
        "  cv2.imwrite(des,result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukrCST3ITpbn",
        "outputId": "4ec401b6-39de-40ba-ff71-626fb230ab1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04.png\n",
            "11.png\n",
            "13.png\n",
            "00.png\n",
            "07.png\n",
            "09.png\n",
            "05.png\n",
            "08.png\n",
            "02.png\n",
            "10.png\n",
            "12.png\n",
            "03.png\n",
            "06.png\n",
            "01.png\n"
          ]
        }
      ]
    }
  ]
}